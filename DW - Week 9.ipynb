{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91008ab4-e897-4ff5-b39d-29b5bbeb0e48",
   "metadata": {},
   "source": [
    "**Title**: Data Wrangling 9.2 Exercises  \n",
    "**Author**: Ryan Weeks  \n",
    "**Date**: 2/8/2025  \n",
    "**Description**:  These exercises focus on working with various data formats in Python, including NumPy arrays, CSV, JSON, Excel, and web scraping with BeautifulSoup. They involve reading, writing, transforming, and extracting meaningful information from structured data sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4f81efb-2dc4-4e16-a0d5-aa5983238732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3\n",
      "0  0.644144  0.380748  0.663048  0.163651\n",
      "1  0.962608  0.346662  0.991751  0.235058\n",
      "2  0.585694  0.406690  0.136234  0.544136\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "np.random.seed(30)\n",
    "\n",
    "# Generate a 3x4 NumPy array with random values\n",
    "array = np.random.rand(3, 4)\n",
    "\n",
    "# Save the array as a CSV file\n",
    "np.savetxt(\"np.csv\", array, delimiter=\",\")\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(\"np.csv\", header=None)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n",
    "\n",
    "# Write the DataFrame to a new CSV file\n",
    "df.to_csv(\"df_output.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55d0e74a-82fc-415b-8b3f-0541b67ab4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of CSV file: 36865 bytes\n",
      "Shape of loaded array: (365, 4)\n",
      "Size of NumPy file: 11808 bytes\n",
      "Size of Pickle file: 12239 bytes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Step 1: Generate a 365x4 NumPy array with random values\n",
    "np.random.seed(30)\n",
    "array = np.random.rand(365, 4)\n",
    "\n",
    "# Step 2: Store the array in a CSV file\n",
    "csv_filename = \"random_data.csv\"\n",
    "np.savetxt(csv_filename, array, delimiter=\",\")\n",
    "\n",
    "# Step 3: Check the size of the CSV file\n",
    "csv_size = os.path.getsize(csv_filename)\n",
    "print(f\"Size of CSV file: {csv_size} bytes\")\n",
    "\n",
    "# Step 4: Save the array in NumPy format\n",
    "npy_filename = \"random_data.npy\"\n",
    "np.save(npy_filename, array)\n",
    "\n",
    "# Step 5: Load the array back from the NumPy file\n",
    "loaded_array = np.load(npy_filename)\n",
    "\n",
    "# Step 6: Check the shape of the loaded array\n",
    "print(f\"Shape of loaded array: {loaded_array.shape}\")\n",
    "\n",
    "# Step 7: Check the size of the NumPy file\n",
    "npy_size = os.path.getsize(npy_filename)\n",
    "print(f\"Size of NumPy file: {npy_size} bytes\")\n",
    "\n",
    "# Step 8: Create a DataFrame from the array\n",
    "df = pd.DataFrame(loaded_array)\n",
    "\n",
    "# Step 9: Save the DataFrame to a pickle file\n",
    "pickle_filename = \"random_data.pkl\"\n",
    "df.to_pickle(pickle_filename)\n",
    "\n",
    "# Step 10: Retrieve the DataFrame from the pickle\n",
    "loaded_df = pd.read_pickle(pickle_filename)\n",
    "\n",
    "# Step 11: Print the size of the pickle file\n",
    "pickle_size = os.path.getsize(pickle_filename)\n",
    "print(f\"Size of Pickle file: {pickle_size} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e353b9a2-2302-42e9-9d49-9edcc0849e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0         1         2         3\n",
      "0    0.644144  0.380748  0.663048  0.163651\n",
      "1    0.962608  0.346662  0.991751  0.235058\n",
      "2    0.585694  0.406690  0.136234  0.544136\n",
      "3    0.518176  0.766855  0.933850  0.089703\n",
      "4    0.195771  0.994194  0.235180  0.238986\n",
      "..        ...       ...       ...       ...\n",
      "360  0.002356  0.603345  0.960803  0.227310\n",
      "361  0.959882  0.363940  0.208686  0.289246\n",
      "362  0.373129  0.805238  0.812730  0.625285\n",
      "363  0.756582  0.562158  0.589113  0.060197\n",
      "364  0.441393  0.424427  0.816909  0.172645\n",
      "\n",
      "[365 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Save the array to an Excel file\n",
    "excel_filename = \"random_data.xlsx\"\n",
    "df = pd.DataFrame(array)  # Convert array to DataFrame\n",
    "df.to_excel(excel_filename, index=False, header=False)\n",
    "\n",
    "# Step 2: Load the Excel file back into a DataFrame\n",
    "df_loaded = pd.read_excel(excel_filename, header=None)\n",
    "\n",
    "# Step 3: Print the DataFrame\n",
    "print(df_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33e3ccea-aafd-4125-92c3-b204eec1f466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Country: Netherlands\n",
      "Updated Country: Wakanda\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# JSON string\n",
    "json_string = '{\"country\":\"Netherlands\",\"dma_code\":\"0\",\"timezone\":\"Europe/Amsterdam\",\"area_code\":\"0\",\"ip\":\"46.19.37.108\",\"asn\":\"AS196752\",\"continent_code\":\"EU\",\"isp\":\"Tilaa V.O.F.\",\"longitude\":5.75,\"latitude\":52.5,\"country_code\":\"NL\",\"country_code3\":\"NLD\"}'\n",
    "\n",
    "# Step 1: Parse the JSON string using json.loads()\n",
    "data = json.loads(json_string)\n",
    "\n",
    "# Step 2: Print the value for the \"country\" column\n",
    "print(f\"Original Country: {data['country']}\")\n",
    "\n",
    "# Step 3: Overwrite the value of \"country\"\n",
    "data[\"country\"] = \"Wakanda\"\n",
    "\n",
    "# Step 4: Print the updated results\n",
    "print(f\"Updated Country: {data['country']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a957f86-cefc-46fa-84f3-0365feceace6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"country\":\"Jabooty\",\"dma_code\":0,\"timezone\":\"Europe\\/Amsterdam\",\"area_code\":0,\"ip\":\"46.19.37.108\",\"asn\":\"AS196752\",\"continent_code\":\"EU\",\"isp\":\"Tilaa V.O.F.\",\"longitude\":5.75,\"latitude\":52.5,\"country_code\":\"NL\",\"country_code3\":\"NLD\"}\n"
     ]
    }
   ],
   "source": [
    "from io import StringIO\n",
    "\n",
    "# Step 1: Use StringIO to read the JSON string as a file-like object\n",
    "json_io = StringIO(f'[{json_string}]')  # Wrap the string in an array for Series\n",
    "\n",
    "# Step 2: Create a Pandas Series from the JSON string\n",
    "series = pd.read_json(json_io).squeeze()  # Convert JSON string to a Series\n",
    "\n",
    "# Step 3: Change the country value to your choice\n",
    "series['country'] = 'Jabooty' \n",
    "\n",
    "# Step 4: Convert the updated Series back to a JSON string\n",
    "updated_json_string = series.to_json()\n",
    "\n",
    "# Step 5: Print the updated JSON string\n",
    "print(updated_json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "322125ba-fe26-4931-bd1a-d57150a9c8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First div\n",
      " <div class=\"tile\">\n",
      "<h4>Development</h4>\n",
      "     0.10.1 - July 2014<br/>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# Parse the HTML\n",
    "soup = BeautifulSoup(open('loremIpsum.html'))\n",
    "\n",
    "# Printing the first <div> tag\n",
    "print(\"First div\\n\", soup.div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "386e987a-9bfc-4a18-b0cf-3e57ef64cd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First div class ['tile']\n"
     ]
    }
   ],
   "source": [
    "# Printing the class attribute of the first <div> tag\n",
    "print(\"First div class\", soup.div['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1d2e0ff6-96ed-41ab-9df0-85b560f17f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First dfn text Quare attende, quaeso.\n"
     ]
    }
   ],
   "source": [
    "# Printing the text of the first <dfn> tag\n",
    "print(\"First dfn text\", soup.dl.dt.dfn.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a0a0e261-5d91-4751-affe-8f42f48f22ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link text loripsum.net URL http://loripsum.net/\n",
      "Link text Poterat autem inpune; URL http://loripsum.net/\n",
      "Link text Is es profecto tu. URL http://loripsum.net/\n"
     ]
    }
   ],
   "source": [
    "for link in soup.find_all('a'):\n",
    "    print(\"Link text\", link.string, \"URL\", link.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b80152c4-e4f1-440d-9139-80b0108da1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['\\n', <h4>Development</h4>, '\\n     0.10.1 - July 2014', <br/>, '\\n']\n",
      "1 ['\\n', <h4>Official Release</h4>, '\\n     0.10.0 June 2014', <br/>, '\\n']\n",
      "2 ['\\n', <h4>Previous Release</h4>, '\\n     0.09.1 June 2013', <br/>, '\\n']\n"
     ]
    }
   ],
   "source": [
    "for i, div in enumerate(soup('div')):\n",
    "    print(i, div.contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "07ea1007-6e53-4bd3-8c10-10edea27f68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Official Version 0.10.0 June 2014\n"
     ]
    }
   ],
   "source": [
    "official_div = soup.find_all(\"div\", id=\"official\")\n",
    "print(\"Official Version\", official_div[0].contents[2].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "44814dd9-22f9-4e1e-8c65-2b45a2023861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# elements with class 3\n"
     ]
    }
   ],
   "source": [
    "# Printing number of elements that have any class attribute\n",
    "print(\"# elements with class\",len(soup.find_all(class_=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "af910573-8e08-4620-84b8-74dacbfb80a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tile classes 2\n"
     ]
    }
   ],
   "source": [
    "tile_class = soup.find_all(\"div\", class_=\"tile\")\n",
    "print(\"# Tile classes\", len(tile_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "92e74029-db1d-4eeb-b038-97b2d18605ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Divs with class containing tile 3\n"
     ]
    }
   ],
   "source": [
    "print(\"# Divs with class containing tile\", len(soup.find_all(\"div\", class_=re.compile(\"tile\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7b98977f-9085-4ec8-a489-af3148832e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CSS selector\n",
      " [<div class=\"notile\">\n",
      "<h4>Previous Release</h4>\n",
      "     0.09.1 June 2013<br/>\n",
      "</div>]\n"
     ]
    }
   ],
   "source": [
    "print(\"Using CSS selector\\n\", soup.select('div.notile'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1dfca5fb-b270-40d8-a9d2-524177a51829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting ordered list list items\n",
      " [<li>Cur id non ita fit?</li>, <li>In qua si nihil est praeter rationem, sit in una virtute finis bonorum;</li>]\n"
     ]
    }
   ],
   "source": [
    "print(\"Selecting ordered list list items\\n\", soup.select(\"ol > li\")[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1cb6e2d9-f749-4a75-b204-8041dd97ea96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second list item in ordered list [<li>In qua si nihil est praeter rationem, sit in una virtute finis bonorum;</li>]\n"
     ]
    }
   ],
   "source": [
    "print(\"Second list item in ordered list\", soup.select(\"ol>li:nth-of-type(2)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b9efeb13-82e4-447f-8d4e-75dfdc2e9b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for text string ['\\n     0.10.1 - July 2014', '\\n     0.10.0 June 2014']\n"
     ]
    }
   ],
   "source": [
    "print(\"Searching for text string\", soup.find_all(string=re.compile(\"2014\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
